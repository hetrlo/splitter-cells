"""
An analysis of the bot's trajectory, to quantify its exploration of the maze

"""

import numpy as np
import matplotlib.pyplot as plt
import random as rd
from scipy.stats import pearsonr
from scipy.ndimage import median_filter
from math import *
from sklearn.neural_network import MLPClassifier
from sklearn import preprocessing

# Functions to load data
def load_positions(path):
    return np.load(path + 'positions.npy')


def load_reservoir_states(path):
    return np.load(path + 'reservoir_states.npy')


def load_orientations(path):
    return np.load(path + 'output.npy')

def load_sensors(path):
    return np.load(path + 'input.npy')

# Standardization of an array : values will be in range [0,1]
def standardize(array):
    array = np.abs(array)
    max_arr = np.max(array)
    min_arr = np.min(array)
    if max_arr==0:
        return array
    if min_arr == max_arr:
        return array / max_arr
    return (array - min_arr) / (max_arr - min_arr)
    

# Computes the percentage of time the bot touches the walls
def walls_collision_percentage():
    sensitivity = 0.05 # sensitivity of the sensors

    path = "/home/heloise/Mnémosyne/splitter-cells/trials/states/"
    sensors = load_sensors(path)
    len_record = len(sensors)
    print(len_record)

    # Determins whether the bot was in a wall at a given step
    def is_collision(sensors_values):
        collision = False
        for val in iter(sensors_values):
            collision = collision or (val < sensitivity)
        return collision
    
    collision = np.array([is_collision(sensors[i]) for i in range(len_record)])
    nb_collisions = np.count_nonzero(collision)
    return (nb_collisions / len_record) * 100

# Trying to fit an esn to compute position from the activity
def preprocess_positions(resolution, positions):
    discrete_positions = np.array([[0 for j in range(resolution[0]+resolution[1])] for i in range(len(positions))])
    for i,pos in enumerate(positions):
        # Computing correspondance between position and indexes in the repartition matrix
        x = floor((pos[0] / 300) * resolution[0])
        y = floor((pos[1] / 500) * resolution[1])
        discrete_positions[i,x] = 1
        discrete_positions[i,y+resolution[0]] = 1
    return discrete_positions

def process_positions(resolution, positions):
    discrete_x = np.array([[0 for j in range(resolution[0])] for i in range(len(positions))])
    discrete_y = np.array([[0 for j in range(resolution[1])] for i in range(len(positions))])
    for i,pos in enumerate(positions):
        # Computing correspondance between position and indexes in the repartition matrix
        x = floor((pos[0] / 300) * resolution[0])
        y = floor((pos[1] / 500) * resolution[1])
        discrete_x[i,x] = 1
        discrete_y[i,y] = 1
    return discrete_x, discrete_y

def plot_comparison_pred_test(resolution, pos_pred, pos_test):
    x_pred, y_pred, x_test, y_test = [], [], [], []
    nonsense_count = 0
    for (pred, pos) in iter(zip(pos_pred, pos_test)):
        pr, po = np.argwhere(pred).ravel(), np.argwhere(pos).ravel()
        if (len(pr) < 2):
            #print("Panic panic, mauvaise prédiction !")
            nonsense_count += 1
            continue
        # Prediction non sense now removed
        else:
            x_pred.append(pr[0])
            y_pred.append(pr[-1] - resolution[0])
            x_test.append(po[0])
            y_test.append(po[-1] - resolution[0])
    # Print percentage of nonsense values
    print("Nonsensical predictions percentage:", 
        nonsense_count / len(pos_pred) * 100)
    # Plotting comparisons for x and y
    x_pred, x_test = np.array(x_pred), np.array(x_test)
    plt.plot(x_pred, color='blue')
    #plt.plot(x_test, color='orange', linestyle=":")
    #plt.plot(np.abs(x_pred-x_test), color='black')
    plt.show()
    y_pred, y_test = np.array(y_pred), np.array(y_test)
    plt.plot(y_pred, color='blue')
    #plt.plot(y_test, color='orange', linestyle=":")
    #plt.plot(np.abs(y_pred-y_test), color='black')
    plt.show()

def plot_pred_pos(xpred, ypred, xtest, ytest):
    x_pred, y_pred, x_test, y_test = [], [], [], []
    nonsense_count = 0
    for xp,yp,xt,yt in iter(zip(xpred, ypred, xtest, ytest)):
        xpi, ypi, xti, yti = np.argwhere(xp).ravel(), np.argwhere(yp).ravel(),np.argwhere(xt).ravel(), np.argwhere(yt).ravel()
        if (len(xpi) < 1) or (len(ypi)) < 1:
            nonsense_count += 1
            continue
        else:
            x_pred.append(xpi[0])
            y_pred.append(ypi[0])
            x_test.append(xti[0])
            y_test.append(yti[0])
    # Print percentage of nonsense values
    print("Nonsensical predictions percentage:", 
        nonsense_count / len(ypred) * 100)
    # Plotting comparisons for x and y
    x_pred, x_test = np.array(x_pred), np.array(x_test)
    plt.plot(x_pred, color='blue')
    #plt.plot(x_test, color='orange', linestyle=":")
    #plt.plot(np.abs(x_pred-x_test), color='black')
    plt.show()
    y_pred, y_test = np.array(y_pred), np.array(y_test)
    plt.plot(y_pred, color='blue')
    #plt.plot(y_test, color='orange', linestyle=":")
    #plt.plot(np.abs(y_pred-y_test), color='black')
    plt.show()

def position_from_activity(resolution, path, nb_train):
    activities = load_reservoir_states(path)
    positions = load_positions(path)

    # Preprocessing positions : (0s and two 1s to indicate x and y)
    (disc_pos_x, disc_pos_y) = process_positions(resolution, positions)
    # Train and test splitting
    act_train, pos_train_x, pos_train_y = activities[:nb_train], disc_pos_x[:nb_train], disc_pos_y[:nb_train]
    act_test, pos_test_x, pos_test_y = activities[nb_train:], disc_pos_x[nb_train:], disc_pos_y[nb_train:]
    # Standardizing activity
    scaler = preprocessing.StandardScaler().fit(act_train)
    act_train = scaler.transform(act_train)
    act_test = scaler.transform(act_test)

    classifier_x = MLPClassifier(solver='adam', alpha=1e-5, 
                               hidden_layer_sizes=(20,),
                                random_state=1, max_iter=200)
    classifier_x.fit(act_train, pos_train_x)

    classifier_y = MLPClassifier(solver='adam', alpha=1e-5, 
                               hidden_layer_sizes=(20,),
                                random_state=1, max_iter=200)
    classifier_y.fit(act_train, pos_train_y)

    # Classification
    pred_x = classifier_x.predict(act_test)
    pred_y = classifier_y.predict(act_test)
    print("Classifier x score:", classifier_x.score(act_test, pos_test_x))
    print("Classifier y score:", classifier_y.score(act_test, pos_test_y))
    plot_pred_pos(pred_x, pred_y, pos_test_x, pos_test_y)

def posfromact(resolution, path, nb_train):
    activities = load_reservoir_states(path)
    positions = load_positions(path)

    # Preprocessing positions : array of (res[0] + res[1]) ints 
    # (0s and two 1s to indicate x and y)
    disc_pos = preprocess_positions(resolution, positions)
    # Train and test splitting
    act_train, pos_train = activities[:nb_train], disc_pos[:nb_train]
    act_test, pos_test = activities[nb_train:], disc_pos[nb_train:]
    # Standardizing activity
    scaler = preprocessing.StandardScaler().fit(act_train)
    act_train = scaler.transform(act_train)
    act_test = scaler.transform(act_test)

    classifier = MLPClassifier(solver='adam', alpha=1e-5, 
                               hidden_layer_sizes=(20,),
                                random_state=1, max_iter=200)
    classifier.fit(act_train, pos_train)

    # Classification
    pos_predicted = classifier.predict(act_test)
    print("Classifier score :", classifier.score(act_test, pos_test))
    plot_comparison_pred_test(resolution, pos_predicted, pos_test)

def position_from_sensors(resolution, path, nb_train):
    sensors = load_sensors(path)
    positions = load_positions(path)
    # Preprocessing positions : array of (res[0] + res[1]) ints 
    # (0s and two 1s to indicate x and y)
    disc_pos = preprocess_positions(resolution, positions)
    # Train and test splitting
    act_train, pos_train = sensors[:nb_train], disc_pos[:nb_train]
    act_test, pos_test = sensors[nb_train:], disc_pos[nb_train:]
    # Standardizing sensors
    scaler = preprocessing.StandardScaler().fit(act_train)
    act_train = scaler.transform(act_train)
    act_test = scaler.transform(act_test)

    classifier = MLPClassifier(solver='sgd', alpha=1e-5, 
                               hidden_layer_sizes=(50,),
                                random_state=1, max_iter=500)
    classifier.fit(act_train, pos_train)

    # Classification
    pos_predicted = classifier.predict(act_test)
    print("Classifier score :", classifier.score(act_test, pos_test))
    plot_comparison_pred_test(resolution, pos_predicted, pos_test)

# Returns an array with the amount of times the bot entered each bin
def exploratory_map(resolution, positions):
    movement_repartition = np.zeros(resolution)

    for pos in iter(positions):
        # Computing correspondance between position and indexes in the repartition matrix
        x = floor((pos[0] / 300) * resolution[0])
        y = floor((pos[1] / 500) * resolution[1])
        movement_repartition[x,y] += 1
    return movement_repartition

def plot_map(explo_map):
    # Normalizing the array
    explo_map /= np.std(explo_map)
    plt.imshow(explo_map.T, cmap='inferno', origin='lower')
    plt.show()

# Average activity in each bin for one neuron
def activity_map(neuron_activity, positions, explo_map, resolution):
    map = np.zeros(resolution)
    for i,pos in enumerate(positions):
        # Computing correspondance between position and indexes in the exploration matrix
        x = floor((pos[0] / 300) * resolution[0])
        y = floor((pos[1] / 500) * resolution[1])
        if explo_map[x,y] != 0:
            map[x,y] += neuron_activity[i] / explo_map[x,y]
        else:
            map[x,y] = 0
    map
    return map

from matplotlib.colors import Normalize
def plot_activity_map(neuron, positions, explo_map, resolution):
    map = activity_map(neuron, positions, explo_map, resolution)
    plt.imshow(map.T, cmap = 'bwr', origin='lower', vmin=-1, vmax=1)
    plt.show()

# Maps the mean neurons activity across the maze (to reveal potential bias)
def show_place_fields(resolution):
    path = "/home/heloise/Mnémosyne/splitter-cells/trials/first_attempt/reservoir_states/"
    res_states = load_reservoir_states(path)
    positions = load_positions(path)

    activity_map = np.zeros(resolution)
    movement_repartition = exploratory_map(resolution, positions)

    for i,pos in enumerate(positions):
        # Computing correspondance between position and indexes in the repartition matrix
        x = floor((pos[0] / 300) * resolution[0])
        y = floor((pos[1] / 500) * resolution[1])
    
        for state in iter(res_states[i]):
            if movement_repartition[x,y] != 0:
                activity_map[x,y] += state / movement_repartition[x,y]
            else:
                activity_map[x,y] = 0

    activity_map /= np.std(activity_map)

    plt.imshow(activity_map.T, cmap='inferno', origin='lower')
    plt.show()



######################################################################################################################################



# Detecting place cells using the Peak method
def place_cells_detection_peak(resolution):
    path = "/home/heloise/Mnémosyne/splitter-cells_results/braitenberg >> pool/maze_other/"
    #path = "/home/heloise/Mnémosyne/splitter-cells/data/RR-LL/no_cues/reservoir_states/"
    r = load_reservoir_states(path)
    res_states = r.T[:50].T[:2100]
    #res_states = np.array([res_states.T[953], res_states.T[1457], res_states.T[323], res_states.T[1251], res_states.T[267]]).T
    #res_states = np.array([res_states.T[81], res_states.T[1486], res_states.T[23], res_states.T[1201]]).T
    positions = load_positions(path)[:2100]
    nb_neurons = len(res_states[0])
    explo_map = exploratory_map(resolution, positions)
    
    # Computing the actual peak for each neuron
    true_peaks = np.array([np.max(np.abs(activity_map(res_states.T[i], positions, explo_map, resolution))) for i in range(nb_neurons)])

    # Computing random peaks by shuffling the activity nb_shuffle times for a neuron
    def random_peaks(neuron_activity, nb_shuffles):
        peaks = np.zeros(nb_shuffles)
        for n in range(nb_shuffles):
            #rd.seed(n) # To generate different shuffles : might be a bad idea
            rd_activity = np.copy(neuron_activity)
            rd.shuffle(rd_activity) # in place
            peaks[n] = np.max(np.abs(activity_map(rd_activity, positions, explo_map, resolution)))
        return peaks
    
    # Computing the 99-percentile for each set of peaks
    nb_shuffle = 500

    peaks = np.array([np.concatenate((np.array([true_peaks[i]]), random_peaks(res_states.T[i], nb_shuffle))) for i in range(nb_neurons)])
    percentiles = [np.percentile(peaks[i], 99) for i in range(nb_neurons)]

    # Only keeping cells with a true peak over the 99-percentile of its peak set
    is_place_cell = [peaks[i,0] >= percentiles[i] for i in range(nb_neurons)]
    place_cells = np.argwhere(is_place_cell)
    return place_cells.ravel()

#########################################################################################################################################

# Detecting place cells using stability method TODO: to be fixed, seems to be irrelevant
def place_cells_detection_stability(resolution):
    #path = "/home/heloise/Mnémosyne/splitter-cells/trials/first_attempt/reservoir_states/"
    #path = "/home/heloise/Mnémosyne/splitter-cells/data/RR-LL/no_cues/reservoir_states/"
    path = "/home/heloise/Mnémosyne/splitter-cells/trials/mix/maze_other/"
    res_states = load_reservoir_states(path).T[:150].T
    #res_states = np.array([res_states.T[953], res_states.T[1457], res_states.T[323], res_states.T[267], res_states.T[1251]]).T
    ##res_states = np.array([res_states.T[81], res_states.T[1486], res_states.T[23], res_states.T[1201]]).T
    positions = load_positions(path)
    nb_neurons = len(res_states[0])

    # Defining halves of the trajectory
    positions_1, positions_2 = positions[:floor(len(positions)/2)], positions[floor(len(positions)/2):]
    res_states_1, res_states_2 = res_states[:floor(len(positions)/2)], res_states[floor(len(positions)/2):]
    # ... And their corresponding exploratory maps
    explo_map_1, explo_map_2 = exploratory_map(resolution, positions_1), exploratory_map(resolution, positions_2)
    
    # Actual activity maps for each neuron
    maps_1 = np.array([activity_map(state, positions_1, explo_map_1, resolution) for state in res_states_1.T])
    maps_2 = np.array([activity_map(state, positions_2, explo_map_2, resolution) for state in res_states_2.T])

    # Actual Pearson correlation coefficient between first section and second section maps
    true_coefs = np.array([pearsonr(maps_1[i].ravel(),maps_2[i].ravel()).statistic for i in range(nb_neurons)])

    # Computing coefficients for random maps by shuffling the activity nb_shuffle times for each neuron
    def random_coefs(m1, nb_shuffles):
        coefs = np.zeros(nb_shuffles)
        maps = rd.choices(maps_2, k=nb_shuffles)
        for n in range(nb_shuffles):
            coefs[n] = pearsonr(m1.ravel(), maps[n].ravel()).statistic
        return coefs
    
    # Computing the 99-percentile for each set of activities
    nb_shuffle = 300
    coefs = np.array([np.concatenate((np.array([true_coefs[i]]), random_coefs(maps_1[i], nb_shuffle))) for i in range(nb_neurons)])
    percentiles = [np.percentile(coefs[i], 95) for i in range(nb_neurons)]

    is_place_cell = [coefs[i,0] >= percentiles[i] for i in range(nb_neurons)]
    place_cells = np.argwhere(is_place_cell)
    return place_cells.ravel()

#############################################################################################################################################

# Radius defines the size of a place field
def place_cells_filter_specificity(resolution, radius):
    path = "/home/heloise/Mnémosyne/splitter-cells_results/braitenberg >> pool/maze_other/"
    #path = "/home/heloise/Mnémosyne/splitter-cells/data/RR-LL/no_cues/reservoir_states/"
    r = load_reservoir_states(path)[:2000]
    res_states = r
    #res_states = np.array([res_states.T[953], res_states.T[1457], res_states.T[323], res_states.T[1251], res_states.T[267]]).T
    #res_states = np.array([res_states.T[81], res_states.T[1486], res_states.T[23], res_states.T[1201]]).T
    positions = load_positions(path)[:2000]
    nb_neurons = len(res_states[0])
    explo_map = exploratory_map(resolution, positions)

    def diff_mean(act_map, radius):
        pos = np.argmax(act_map)
        pos_max = [floor(pos/len(act_map[0])), pos%len(act_map[0])]
        map_field = np.zeros(resolution)
        #map_comp = np.zeros((resolution))
        for i in range(resolution[0]):
            for j in range(resolution[1]):
                # In the place field
                if (pos_max[0]-radius <= i <= pos_max[0]+radius) and (pos_max[1]-radius <= j <= pos_max[1]+radius):
                    map_field[i,j] = act_map[i,j]
                # Outside
                #else:
                    #map_comp[i,j] = act_map[i,j]
        
        mf_non_zero = map_field[map_field > 0]
        mc_non_zero = act_map[act_map > 0]
        
        # Testing whether any array is empty (given that all values are now non zero)
        if not mf_non_zero.any():
            peak_field = 0
        else:
            peak_field = np.sum(mf_non_zero)
        if not mc_non_zero.any():
            peak_comp = 0
        else:
            peak_comp = np.sum(mc_non_zero)
        
        return [peak_field, peak_comp]
    

    # Array with each neurons mean activity across the maze
    activity_maps = np.array([activity_map(state, positions, explo_map, resolution) for state in res_states.T])
    
    delta_peaks = np.array([diff_mean(activity_maps[i], radius) for i in range(nb_neurons)])

    print(delta_peaks[16])

    is_place_cell = [delta_peaks[i,0] > 0.9 * delta_peaks[i,1] for i in range(nb_neurons)]
    #is_place_cell = [delta_peaks[i,0] > 0.4 and delta_peaks[i,1] <= 0 for i in range(nb_neurons)]
    place_cells = np.argwhere(is_place_cell)
    return place_cells.ravel()

#################################################################################################################################

def place_cells_stability_filter(resolution):
    #path = "/home/heloise/Mnémosyne/splitter-cells/trials/first_attempt/reservoir_states/"
    #path = "/home/heloise/Mnémosyne/splitter-cells/data/RR-LL/no_cues/reservoir_states/"
    path = "/home/heloise/Mnémosyne/splitter-cells/trials/trained_maze_other__new_maze/"
    r = load_reservoir_states(path)
    res_states = r[450:1500]
    #res_states = np.array([res_states.T[953], res_states.T[1457], res_states.T[323], res_states.T[1251], res_states.T[267]]).T
    #res_states = np.array([res_states.T[81], res_states.T[1486], res_states.T[23], res_states.T[1201]]).T
    positions = load_positions(path)[450:1500]
    nb_neurons = len(res_states[0])

    def activity_variance(activity, resolution):
        activities = [[[] for j in range(resolution[1])] for i in range(resolution[0])]
        for i,pos in enumerate(positions):
            # Computing correspondance between position and indexes in the repartition matrix
            x = floor((pos[0] / 300) * resolution[0])
            y = floor((pos[1] / 500) * resolution[1])
            activities[x][y].append(activity[i])
        for i, l in enumerate(activities):
            for j, act in enumerate(l):
                if act == []:
                    activities[i][j] = nan # when it's a wall
                else:
                    activities[i][j] = np.var(act)
        activities = [[x for x in activities[i] if x==x] for i in range(len(activities))]
        return activities
    
    # Mean for inhomogeneous tabs
    def mean(tab):
        val = 0
        nb_elem = 0
        for x in iter(tab):
            for y in iter(x):
                nb_elem += 1
                val += y
        return val/nb_elem
    
    sum_variances = [-1*mean(activity_variance(state, resolution)) for state in res_states.T]        
    percentile = np.percentile(sum_variances, 99)
    is_place_cell = [sum_variances[i] >= percentile for i in range(nb_neurons)]
    place_cells = np.argwhere(is_place_cell)
    return place_cells.ravel()


path = "/home/heloise/Mnémosyne/splitter-cells_results/braitenberg >> pool/maze_other/"
#path = "/home/heloise/Mnémosyne/splitter-cells/data/RR-LL/no_cues/reservoir_states/"
state = load_reservoir_states(path).T[454].T[:2000]
positions = load_positions(path)[:2000]

#exploratory_map((6,10))
#print(walls_collision_percentage())
#show_place_fields((6,10))
#plot_activity_map(state, positions, exploratory_map((12,20), positions), (12,20))

#place_cells_peak = place_cells_detection_peak((12,20))
#print(place_cells_peak)

#place_cells_stab = place_cells_detection_stability((12,20))
#print(place_cells_stab)

#place_cells_spec_fliltered = place_cells_filter_specificity((12,20), 1)
#print(place_cells_spec_fliltered)

#pc_stab_fil = place_cells_stability_filter((36,60))
#print(pc_stab_fil)

#plot_derivate_activity()
position_from_activity((12,20), path, 5000)
#position_from_sensors((12,20), path, 4500)